{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured Data Classification \n",
    "This project analyzes a structured dataset with **1,251 rows** and **12 columns** provided as a raw text file with **no column descriptions**. The target `label` is an integer from **0–4**, while the remaining columns contain messy string values (units, mixed numeric formats, and categorical text).  \n",
    "\n",
    "Goal: convert the raw file into a fully numeric modeling table, explore feature–label relationships, and compare baseline classifiers using cross-validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'anpantva_data.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ttest_ind\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m df_raw \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43manpantva_data.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m df_raw\u001b[38;5;241m.\u001b[39mshape, df_raw\u001b[38;5;241m.\u001b[39mcolumns\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'anpantva_data.txt'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy.stats import ttest_ind\n",
    "import copy\n",
    "df_raw = pd.read_csv(\"anpantva_data.txt\", sep=\"\\t\")\n",
    "df_raw.shape, df_raw.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset & Assumptions\n",
    "\n",
    "Because the dataset ships with **no metadata**, the first step is to infer structure from observed patterns:\n",
    "\n",
    "- `label` appears to be a **5-class target** (0–4).\n",
    "- Several feature columns look numeric but are stored as **strings**, sometimes with units (e.g., `\"402 kg\"`, `\"922 m\"`).\n",
    "- Some columns contain **categorical tokens** such as sports and animals, including multi-label cases (e.g., `\"dog,cat\"`).\n",
    "\n",
    "**Hypothesis:** after cleaning and encoding, some features will show clear separation across label classes.\n",
    "\n",
    "**Workflow:**\n",
    "1. Inspect raw formats + missingness  \n",
    "2. Clean and transform into numeric feature matrix  \n",
    "3. Visualize trends (boxplots, scatter, correlation)  \n",
    "4. Compare Logistic Regression, KNN, and Decision Tree using 5-fold CV  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.head(5)\n",
    "df_raw.dtypes\n",
    "df_raw.isna().sum().sort_values(ascending=False).head(12)\n",
    "for col in df_raw.columns:\n",
    "    sample = df_raw[col].astype(str).head(3).tolist()\n",
    "    print(col, \"->\", sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning & Feature Engineering\n",
    "\n",
    "Observed raw patterns:\n",
    "\n",
    "- **Unit strings** (e.g., `\"402 kg\"`, `\"922 m\"`) → extract numeric portion\n",
    "- **Numeric-like strings** → coerce to numeric\n",
    "- **Categorical sports (`col_02`)** → normalize + one-hot encode\n",
    "- **Multi-label animals (`col_03`)** → split + multi-hot encode\n",
    "- **Missing / malformed values** → convert to NaN, then impute using median (numeric columns only)\n",
    "\n",
    "After preprocessing, the dataset becomes fully numeric and ready for modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean raw DataFrame by parsing numeric-like strings, imputing missing values,\n",
    "    and encoding categorical columns (sport and animal).\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # 1) Parse object columns containing numbers into numeric (unit stripping)\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == object:\n",
    "            extracted = df[col].astype(str).str.extract(r'(-?\\d+\\.?\\d*)', expand=False)\n",
    "            if extracted.notna().any():\n",
    "                df[col] = pd.to_numeric(extracted, errors='coerce')\n",
    "\n",
    "    # 2) Impute numeric NaNs with median (excluding label)\n",
    "    numeric_cols = df.select_dtypes(include='number').columns.drop('label', errors='ignore')\n",
    "    for col in numeric_cols:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "    # 3) One-hot encode sport column\n",
    "    if 'col_02' in df.columns:\n",
    "        df['col_02'] = (\n",
    "            df['col_02']\n",
    "            .astype(str)\n",
    "            .str.strip()\n",
    "            .str.lower()\n",
    "            .replace({'?': 'missing', 'nan': 'missing'})\n",
    "        )\n",
    "        df = pd.get_dummies(df, columns=['col_02'], prefix='sport')\n",
    "\n",
    "    # 4) Multi-hot encode animal column\n",
    "    if 'col_03' in df.columns:\n",
    "        df['col_03_clean'] = (\n",
    "            df['col_03']\n",
    "            .fillna('')\n",
    "            .replace('?', '')\n",
    "            .astype(str)\n",
    "            .str.lower()\n",
    "            .str.strip()\n",
    "            .str.replace(r'\\s*,\\s*', ',', regex=True)\n",
    "        )\n",
    "        animal_dummies = df['col_03_clean'].str.get_dummies(sep=',').add_prefix('animal_')\n",
    "        df = pd.concat([df, animal_dummies], axis=1)\n",
    "        df.drop(columns=['col_03', 'col_03_clean'], inplace=True)\n",
    "\n",
    "    # Ensure label is numeric if present\n",
    "    if \"label\" in df.columns:\n",
    "        df[\"label\"] = pd.to_numeric(df[\"label\"], errors=\"coerce\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = clean_data(df_raw)\n",
    "\n",
    "print(\"Raw shape:\", df_raw.shape)\n",
    "print(\"Clean shape:\", df_clean.shape)\n",
    "df_clean.head(3)\n",
    "df_clean.dtypes.value_counts()\n",
    "df_clean.isna().sum().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**Result:** after cleaning and encoding, the dataset contains **only numeric features**, with missing values imputed, and is ready for modeling. The final feature set includes numeric columns plus one-hot and multi-hot indicators for sports and animals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis \n",
    "Goal: identify which features separate the 5 label classes and whether relationships between features suggest linear vs non-linear decision boundaries.  \n",
    "I focus on three visuals:\n",
    "1) distribution shifts by label (boxplots)  \n",
    "2) 2D clustering between key features (scatter)  \n",
    "3) overall feature relationships (correlation heatmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Feature Distrubutions by Label: Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(12, 9))\n",
    "axes = axes.flatten()\n",
    "for ax, col in zip(axes, numeric_cols):\n",
    "    data = [df_clean[df_clean.label == k][col] for k in range(5)]\n",
    "    ax.boxplot(data, tick_labels=[0, 1, 2, 3, 4])\n",
    "    ax.set_title(col)\n",
    "    ax.set_xlabel(\"class\")\n",
    "    ax.set_ylabel(col)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "- col_00 and col_10 show the clearest separation: several classes occupy distinct value ranges.\n",
    "- Features like col_01 and col_04 show gradually shifting medians, suggesting consistent signal across classes.\n",
    "- Some features have heavy overlap and likely contribute less on their own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Pairwise Seperation: Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 5))\n",
    "plt.scatter(\n",
    "    df_clean[\"col_05\"],\n",
    "    df_clean[\"col_06\"],\n",
    "    c=df_clean[\"label\"],\n",
    "    cmap=\"tab10\",\n",
    "    alpha=0.7\n",
    ")\n",
    "plt.xlabel(\"col_05\")\n",
    "plt.ylabel(\"col_06\")\n",
    "plt.title(\"col_05 vs. col_06 by class\")\n",
    "plt.colorbar(ticks=range(5), label=\"class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each point represents one observation. After testing all combinations, this plot shows the strongest class structure in just two dimensions: classes form distinct clusters occupying different regions of the plane. \n",
    "\n",
    "Notably, class 2 concentrates in the bottom-left (low `col_05`, low `col_06`), class 4 in the bottom-right (high `col_05`, low `col_06`), class 0 in the upper-right (high `col_05`, high `col_06`), class 3 near the top (very high `col_06`), and class 1 in the mid-left region. \n",
    "\n",
    "There is some overlap at cluster boundaries (especially between classes 1 and 3, and between 0 and 3), suggesting that these pairs are most likely to be confused when using only these two features.\n",
    "\n",
    "The clear 2D separation helps explain why even simple classifiers achieve very high accuracy after cleaning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Correlation Insights : Heatmap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_clean[numeric_cols].corr()\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.imshow(corr, vmin=-1, vmax=1)\n",
    "plt.xticks(range(len(numeric_cols)), numeric_cols, rotation=90)\n",
    "plt.yticks(range(len(numeric_cols)), numeric_cols)\n",
    "plt.colorbar(label=\"Pearson r\")\n",
    "plt.title(\"Numeric feature correlations\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation matrix highlights several strong feature relationships. In particular, `col_06` and `col_07` show a **strong negative correlation**, indicating that as one increases the other tends to decrease. The pair `col_05` and `col_06` shows a **positive association**, which is consistent with the structure seen in the `col_05` vs. `col_06` scatter plot (classes separate partly along these axes). \n",
    "\n",
    "At the same time, many feature pairs exhibit **low to moderate correlation**, suggesting that multiple columns contribute complementary information rather than all encoding the same signal. This mix of correlated and relatively independent features helps explain why simple models can perform well while still benefiting from combining multiple predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modeling\n",
    "To evaluate how well the cleaned features predict the 5-class label, I compared three classifiers:\n",
    "\n",
    "- **Logistic Regression**: interpretable linear baseline\n",
    "- **K-Nearest Neighbors (KNN)**: simple non-parametric baseline sensitive to local structure\n",
    "- **Decision Tree**: captures non-linear splits and feature interactions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifiers():\n",
    "    return [\n",
    "        LogisticRegression(max_iter=1000, random_state=42),  # baseline linear\n",
    "        KNeighborsClassifier(n_neighbors=5),                 # simple distance-based\n",
    "        DecisionTreeClassifier(random_state=42, max_depth=None)  # flexible non-linear\n",
    "    ]\n",
    "\n",
    "def cross_fold_validation(classifier, frame, folds):\n",
    "    df = frame.reset_index(drop=True)\n",
    "    n = len(df)\n",
    "    fold_size = n // folds\n",
    "\n",
    "    scores = []\n",
    "    for i in range(folds):\n",
    "        start = i * fold_size\n",
    "        # Last fold takes any remainder\n",
    "        end = n if i == folds - 1 else (i + 1) * fold_size\n",
    "\n",
    "        test_df = df.iloc[start:end]\n",
    "        train_df = pd.concat([df.iloc[:start], df.iloc[end:]], ignore_index=True)\n",
    "\n",
    "        X_train, y_train = train_df.drop(columns=\"label\"), train_df[\"label\"]\n",
    "        X_test, y_test = test_df.drop(columns=\"label\"), test_df[\"label\"]\n",
    "\n",
    "        # Fresh copy of the classifier\n",
    "        clf = copy.deepcopy(classifier)\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        scores.append(clf.score(X_test, y_test))\n",
    "\n",
    "    return scores\n",
    "\n",
    "def significance_test(a_values, b_values, p_value):\n",
    "    t_stat, p_val = ttest_ind(a_values, b_values, equal_var=True)\n",
    "    return p_val < p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_classifiers = create_classifiers()\n",
    "\n",
    "results = []  # for a clean summary table\n",
    "scores_by_model = {}  # name -> fold scores\n",
    "\n",
    "for clf in my_classifiers:\n",
    "    name = type(clf).__name__\n",
    "    fold_scores = cross_fold_validation(clf, df_clean, 5)\n",
    "    scores_by_model[name] = fold_scores\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Fold Accuracies\": fold_scores,\n",
    "        \"Mean Accuracy\": float(np.mean(fold_scores)),\n",
    "        \"Std Dev\": float(np.std(fold_scores, ddof=1)),  # sample std\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(\"Mean Accuracy\", ascending=False)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.10\n",
    "\n",
    "names = list(scores_by_model.keys())\n",
    "for i in range(len(names)):\n",
    "    for j in range(i + 1, len(names)):\n",
    "        a, b = names[i], names[j]\n",
    "        t_stat, p_val = ttest_ind(scores_by_model[a], scores_by_model[b], equal_var=True)\n",
    "        print(f\"{a} vs {b}: p={p_val:.3f}  -> significant={p_val < alpha}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation Setup\n",
    "\n",
    "I evaluated three classifiers using **5-fold cross-validation** on the cleaned dataset.  \n",
    "For each fold, the model trains on 80% of the data and tests on the remaining 20%, producing five accuracy scores per classifier. I summarize performance using the mean and standard deviation across folds to compare both accuracy and stability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analysis\n",
    "\n",
    "### 5.1 Cross-Validation Differences (Significance Check)\n",
    "\n",
    "To sanity-check whether performance gaps between models are likely due to chance, I ran **pairwise t-tests** on the **5-fold cross-validation accuracy scores** (α = 0.10). Because each model produces only five scores, this should be treated as a **rough heuristic** rather than a definitive statistical conclusion.\n",
    "\n",
    "- **Logistic Regression vs. KNN:** statistically significant (p < 0.10), suggesting KNN underperforms more consistently across folds.\n",
    "- **Logistic Regression vs. Decision Tree:** not statistically significant (p ≈ 0.12), consistent with their similar mean accuracies.\n",
    "- **Decision Tree vs. KNN:** statistically significant (p < 0.10), indicating the tree model outperforms KNN across folds.\n",
    "\n",
    "### 5.2 Why Logistic Regression Performs Best\n",
    "\n",
    "After cleaning and encoding, the feature space shows strong class structure (e.g., clear distribution shifts in boxplots and cluster separation in scatter plots). This supports why **Logistic Regression** performs so well: much of the separation appears close to **linearly separable** in the engineered feature space, so a simple linear decision boundary is sufficient and stable.\n",
    "\n",
    "The **Decision Tree** performs competitively by capturing non-linear thresholds and handling outliers, but it shows higher variance across folds due to sensitivity to training splits. **KNN** performs worst and is the most variable, likely because it is sensitive to local overlap near class boundaries and depends heavily on neighborhood structure.\n",
    "\n",
    "### 5.3 Limitations and Improvements\n",
    "\n",
    "- **Metric choice:** Accuracy may hide class-specific weaknesses if classes are imbalanced. In future evaluation, I would report **macro F1-score**, per-class precision/recall, and a confusion matrix.\n",
    "- **Model tuning:** I used minimal tuning (e.g., `k=5` for KNN; default tree depth). A hyperparameter sweep (KNN `k`, tree `max_depth`/pruning) may yield small gains.\n",
    "- **Data validation:** A few anomalous entries (e.g., negative distances) suggest additional cleaning rules or automated validation could improve robustness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "\n",
    "This project transformed a raw, undocumented dataset (11 messy feature columns + label) into a clean modeling table with **36 numeric predictors**, including parsed numeric values and encoded categorical indicators. Exploratory visualizations (boxplots, scatter plots, and a correlation heatmap) revealed strong class structure and helped identify which features carried the most signal.\n",
    "\n",
    "Across three classifiers evaluated with **5-fold cross-validation**, all models performed well, suggesting that the engineered features separate classes effectively. **Logistic Regression** achieved the best overall performance and the lowest variance across folds, making it the simplest and most stable choice for this dataset. Decision Trees were competitive but slightly less stable, while KNN was both less accurate and more sensitive to fold composition.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "If I continued this work, I would:\n",
    "- add stronger evaluation metrics (macro F1, confusion matrices, per-class recall)\n",
    "- implement systematic hyperparameter tuning (KNN `k`, tree depth/pruning)\n",
    "- test ensemble methods (Random Forests, Gradient Boosting / XGBoost)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
